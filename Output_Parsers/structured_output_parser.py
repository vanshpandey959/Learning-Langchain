# from langchain_google_genai import ChatGoogleGenerativeAI
# from dotenv import load_dotenv
# from langchain_core.prompts import PromptTemplate
# from langchain.

# load_dotenv()

# # Define the model
# model = ChatGoogleGenerativeAI(
#     model="models/gemini-flash-latest",
# )

# schema = [
#     ResponseSchema(name='fact_1', description='Fact 1 about the topic'),
#     ResponseSchema(name='fact_2', description='Fact 2 about the topic'),
#     ResponseSchema(name='fact_3', description='Fact 3 about the topic'),
# ]

# parser = StructuredOutputParser.from_response_schemas(schema)

# template = PromptTemplate(
#     template="""
# Give 3 facts about {topic}.

# {format_instructions}
# """,
#     input_variables=["topic"],
#     partial_variables={
#         "format_instructions": parser.get_format_instructions()
#     },
# )

# chain = template | model | parser

# result = chain.invoke({"topic": "black hole"})

# print(result)